du -h --max-depth=2 /data1/jkitony/
aws s3 ls s3://salk-tm-dev/Sbic/pangenome_2024/assemblies/ --recursive --human-readable --summarize
tar -czvf Sbic50_svim_vcf.tar.gz -C /data1/jkitony/Sorghum/graph_pangenome2025/fiftygenomes/TenChrFastaCleaned/temp/svim_cutesv_results Sbic50_svim_vcf_dir
tar -czvf Sbic50_merged_sv.vcf.tar.gz merged_svs.vcf

aws s3 cp s3://salk-tm-raw/reads/Sbic_PI156549/Sbic_PI156549.pb_HiFi.R000-786.L005-388.bam .
aws s3 cp s3://salk-tm-dev/Sbic/bams/SbicPI543243_PH256.bam .


# PDF

pdftk Kitony_resume2025_Martin_LutherKing_COVER.pdf Kitony_resume2025_Martin_LutherKing.pdf PhD.pdf MSC.pdf cat output KITONY_MLK_10G-3.pdf

sudo mkdir -p /mnt/f
sudo mount -t drvfs F: /mnt/f

aws s3 ls s3://salk-tm-dev/Sbic/ --recursive --human-readable --summarize > s3_size_summary.txt

#duplicates
#List all file paths
aws s3 ls s3://salk-tm-dev/Sbic/ --recursive --output text | awk '{print $4}' > all_files.txt
# Extract just the file names (not paths)
awk -F/ '{print $NF}' all_files.txt > file_names_only.txt

# Find duplicate file names
sort file_names_only.txt | uniq -d > duplicated_names.txt


################
#screen 
##############
screen -S pankmersbic50
screen -ls
screen -r
screen -X -S 1740766.edta_nature quit
Ctrl + A, then Ctrl + D
screen -X -S session_id quit


